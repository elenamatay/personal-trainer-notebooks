{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxCkB_DXTHzf"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hny4I-ODTIS6"
   },
   "source": [
    "# Prompt Library Example - Video2Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nLS57E2TO5y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebooks demostrates how to log requests to Vertex AI LLM and Imagen generation models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvKl-BtQTRiQ"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwFMpIMrTV_4"
   },
   "source": [
    "### Install Vertex AI SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYUu8VMdJs3V",
    "outputId": "09f781ab-05a9-4d46-c827-48cc0d88e737",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet --upgrade  google-cloud-aiplatform google-cloud-bigquery google-cloud-storage pillow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z",
    "tags": []
   },
   "source": [
    "### Restart current runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, it is recommended to restart the runtime. Run the following cell to restart the current kernel.\n",
    "\n",
    "The restart process might take a minute or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRvKdaPDTznN",
    "outputId": "8e38549f-518c-40da-fd73-9e47994ca3a2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "import time\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIvVfyyhTPKi",
    "tags": []
   },
   "source": [
    "After the restart is complete, continue to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybBXSukZkgjg"
   },
   "source": [
    "### Define Google Cloud project information\n",
    "\n",
    "If you don't know your project ID, try the following:\n",
    "\n",
    "- Run gcloud config list\n",
    "- Run gcloud projects list\n",
    "- See the support page: Locate the project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5gUjJ42Nh5kf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Define project information\n",
    "PROJECT_ID = \"testing-elena\"  # @param {type:\"string\"}\n",
    "LOCATION = \"europe-west4\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare BigQuery and Cloud Storage Objects\n",
    "\n",
    "The following code should be only executed once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROMPT_LIBRARY_BUCKET_NAME = f\"genai-elena\" # @param {type:\"string\"} \n",
    "BUCKET_URI = f\"gs://{PROMPT_LIBRARY_BUCKET_NAME}\" # Bucket and folders should be already created\n",
    "\n",
    "#IMAGE_GCS_PATH = f\"gs://{PROMPT_LIBRARY_BUCKET_NAME}/multimodal-video/gym-exercises/prompt-library/wireframes/*\"  # @param {type:\"string\"}\n",
    "DATASET_ID = \"gemini_videos\"\n",
    "#IMAGE_TABLE = \"wireframes\"  # @param {type:\"string\"}\n",
    "PROMPT_LOGS_TABLE = \"prompt_logs\"  # @param {type:\"string\"}\n",
    "CONNECTION_ID = \"gemini-videos-storage-conn\" # @param {type:\"string\"}\n",
    "\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
    "os.environ[\"LOCATION\"] = LOCATION\n",
    "os.environ[\"CONNECTION_ID\"] = CONNECTION_ID\n",
    "os.environ[\"BUCKET_URI\"] = BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a connection to access Cloud Storage\n",
    "More info to be found in the [doc](https://cloud.google.com/bigquery/docs/create-cloud-resource-connection#create-cloud-resource-connection).\n",
    "\n",
    "After connection is setup, grant:\n",
    "- roles/bigquery.connectionAdmin\n",
    "- roles/storage.objectViewer\n",
    "\n",
    "more info: [doc](https://cloud.google.com/bigquery/docs/create-cloud-resource-connection#access-storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to BigQuery! This script will walk you through the \n",
      "process of initializing your .bigqueryrc configuration file.\n",
      "\n",
      "First, we need to set up your credentials if they do not \n",
      "already exist.\n",
      "\n",
      "Setting project_id testing-elena as the default.\n",
      "\n",
      "BigQuery configuration complete! Type \"bq\" to get started.\n",
      "\n",
      "Connection 1080686785400.europe-west4.gemini-videos-storage-conn successfully created\n"
     ]
    }
   ],
   "source": [
    "! bq mk --connection --location=$LOCATION --project_id=$PROJECT_ID --connection_type=CLOUD_RESOURCE $CONNECTION_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection testing-elena.europe-west4.gemini-videos-storage-conn\n",
      "\n",
      "                          name                            friendlyName   description    Last modified         type        hasCredential                                             properties                                            \n",
      " ------------------------------------------------------- -------------- ------------- ----------------- ---------------- --------------- ------------------------------------------------------------------------------------------------ \n",
      "  1080686785400.europe-west4.gemini-videos-storage-conn                                24 May 07:00:08   CLOUD_RESOURCE   False           {\"serviceAccountId\": \"bqcx-1080686785400-o3pd@gcp-sa-bigquery-condel.iam.gserviceaccount.com\"}  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "! bq show --connection $PROJECT_ID.$LOCATION.$CONNECTION_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BigQuery Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Preparation\n",
    "Input data should be stored in a BigQuery table.\n",
    "\n",
    "Image data\n",
    "Image columns need to contain image data encoded to base64.\n",
    "\n",
    "BigQuery object tables make it simple to import images from outside sources to BigQuery. [Read more about object tables here](https://cloud.google.com/bigquery/docs/object-table-introduction).\n",
    "The object table can then be encoded as base64.\n",
    "\n",
    "Below is an example of creating an object table with images from a GCS bucket and encoding those images to base64. To do this, there must be a [connection to Cloud Storage](https://cloud.google.com/bigquery/docs/connections-api-intro).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Results: <google.cloud.bigquery.table._EmptyRowIterator object at 0x2877771d0>\n",
      "Job Results: <google.cloud.bigquery.table._EmptyRowIterator object at 0x287a72ba0>\n",
      "Job Results: <google.cloud.bigquery.table._EmptyRowIterator object at 0x287a73290>\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "import time\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Creates the dataset\n",
    "job = bq_client.query(f\"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}`\n",
    "  OPTIONS(\n",
    "    location = '{LOCATION}', \n",
    "    description = 'Dataset that contains prompt data.'\n",
    "  )\n",
    "\"\"\")\n",
    "print(f\"Job Results: {job.result()}\")\n",
    "    \n",
    "# Creates the object table.\n",
    "job = bq_client.query(f\"\"\"\n",
    "CREATE OR REPLACE EXTERNAL TABLE `{PROJECT_ID}.{DATASET_ID}.{IMAGE_TABLE}`\n",
    "                WITH CONNECTION `{LOCATION}.{CONNECTION_ID}`\n",
    "                OPTIONS(\n",
    "                  object_metadata = 'SIMPLE',\n",
    "                  uris = ['{IMAGE_GCS_PATH}']\n",
    "                )\"\"\")\n",
    "print(f\"Job Results: {job.result()}\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Creates the prompt audit table.\n",
    "                                                                                                                              \n",
    "job = bq_client.query(f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.{PROMPT_LOGS_TABLE}`\n",
    "(\n",
    "  uuid STRING NOT NULL,\n",
    "  date DATE DEFAULT CURRENT_DATE(),\n",
    "  ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),\n",
    "  experiment STRING,\n",
    "  iteration INT64,\n",
    "  user STRING DEFAULT SESSION_USER(),\n",
    "  type STRING,\n",
    "  model_name STRING OPTIONS(description=\"Name of the model\"),\n",
    "  temperature NUMERIC,\n",
    "  prompt STRING NOT NULL,\n",
    "  input_video_path STRING,\n",
    "  output_text STRING\n",
    ")\n",
    "PARTITION BY DATE(_PARTITIONTIME)\n",
    "OPTIONS(\n",
    "  description=\"A table that contains prompt logs\"\n",
    ")\n",
    "\"\"\")\n",
    "print(f\"Job Results: {job.result()}\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "import io    \n",
    "    \n",
    "def log_to_bigquery(project_id, dataset_id, table_id, uuid, prompt, experiment, iteration, user, input_video, model_output, \n",
    "                    model_name, temperature, token_limit, top_k, top_p):\n",
    "    \"\"\"Logs the entire execution context and the call to GenAI model using the BQ table\"\"\"\n",
    "    \n",
    "    # Construct a BigQuery client object.\n",
    "    client = bigquery.Client()\n",
    "\n",
    "\n",
    "\n",
    "    # Set up your project, dataset, and table references\n",
    "    \n",
    "    # Construct the fully qualified table reference\n",
    "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "    # Prepare your data as a list of dictionaries (JSON-like format)\n",
    "    rows_to_insert = [{\"uuid\": str(uuid), \"prompt\": prompt, \"experiment\": experiment, \"user\": user, \"model_output\": model_output,\n",
    "        \"model_name\": model_name, \"temperature\": temperature, \"token_limit\": token_limit, \"top_k\": top_k, \"top_p\": top_p\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    errors = client.insert_rows_json(table_ref, rows_to_insert)  # Make an API request.\n",
    "    if errors == []:\n",
    "        print(f\"New rows have been added. Total number {len(rows_to_insert)}\")\n",
    "    else:\n",
    "        print(\"Encountered errors while inserting rows: {}\".format(errors))\n",
    "\n",
    "def log_model_output(project_id, dataset_id, table_id, uuid, prompt, experiment, user, type, model_output, \n",
    "                    model_name, temperature, token_limit, top_k, top_p):   \n",
    "    \"\"\"Logs the entire context in BQ\"\"\"\n",
    "    \n",
    "    log_to_bigquery(project_id, dataset_id, table_id, uuid, prompt, experiment, user, model_output, model_name, temperature, token_limit, top_k, top_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample call to save the context of the Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid as uuid_lib\n",
    "from vertexai.preview.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")\n",
    "import vertexai\n",
    "\n",
    "uuid = uuid_lib.uuid4()\n",
    "\n",
    "uuid = str(uuid)\n",
    "experiment = \"preparation\"\n",
    "user = \"elenamatay@google.com\"   # VERY IMPORTANT\n",
    "type = \"text2text\"\n",
    "model_name = \"gemini-pro\"\n",
    "seed = None\n",
    "region = LOCATION\n",
    "project_id = PROJECT_ID\n",
    "dataset_id = DATASET_ID\n",
    "table_id = PROMPT_LOGS_TABLE\n",
    "negative_prompt = None\n",
    "temperature = 0.1\n",
    "token_limit = 8192\n",
    "top_k = 32\n",
    "top_p = 1.0\n",
    "\n",
    "MODEL_LOCATION=\"us-central1\" # might only support US for a time being\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=MODEL_LOCATION)\n",
    "\n",
    "model = GenerativeModel(model_name)\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=temperature,\n",
    "    top_p=top_p,\n",
    "    top_k=top_k,\n",
    "    candidate_count=1,\n",
    "    max_output_tokens=token_limit,\n",
    ")\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are the creative copywriter and graphical designer working for Digital Agency. Your job is to design a display ad for the insurance company. The campaign is insurance for car. Target group 30-40 years old living in a big city. Target SUV owners. The output should be a prompt for the text2image model. Create hyperrealistic 4k pictures shot by a profesional photographer using Canon 5d. The prompt should be very descriptive and no longer than 20 words.\n",
    "\n",
    "Pictures used for insipiration:\n",
    "Picture 1: A young woman is sitting on the back of her car, looking at her phone. She is wearing a red beanie, a brown and white jacket, and blue jeans. The car is parked on a snowy road, and there are trees and mountains in the background. The sun is setting, and the sky is a pink and purple color.\n",
    "Picture 2: This is a picture of a man sitting in the driver's seat of a car. He is smiling and looking at the camera. He is wearing a green winter coat with a fur collar. The car is black and the interior is black leather. The man has his hands on the steering wheel.\n",
    "Picture 3: This picture shows a woman and a son, leaning in towards each other with their foreheads almost touching. They are both wearing winter clothes and the background is blurred.\n",
    "Picture 4: A man is fueling his car at a gas station. He is wearing a black jacket and has a beard. The car is a black Ford Focus. The gas station is a Repsol station\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config=generation_config,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "model_output = response.text\n",
    "print(model_output)\n",
    "\n",
    "log_model_output(project_id, dataset_id, table_id, uuid, prompt, experiment, user, type, model_output, model_name, temperature, token_limit, top_k, top_p)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
